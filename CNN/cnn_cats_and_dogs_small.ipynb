{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path 지정 \n",
    "train_dir='./cats_and_dogs_small/train'\n",
    "train_cats_dir=os.path.join(train_dir,'cats')\n",
    "train_dogs_dir=os.path.join(train_dir,'dogs')\n",
    "\n",
    "test_dir='./cats_and_dogs_small/test'\n",
    "test_cats_dir=os.path.join(test_dir,'cats')\n",
    "test_dogs_dir=os.path.join(test_dir,'dogs')\n",
    "\n",
    "val_dir='./cats_and_dogs_small/val'\n",
    "val_cats_dir=os.path.join(val_dir,'cats')\n",
    "val_dogs_dir=os.path.join(val_dir,'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 (증대x, 원본 데이터에 약간 변화를 줘서 다양성을 늘림)\n",
    "train_datagen=ImageDataGenerator(rescale=1./255, # 값을 0~1사이로 바꿈(min-max scaler)\n",
    "                                shear_range=0.2, # 찌그러트림\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True) # 수평 방향으로 flip하는가 \n",
    "# 테스트 데이터에 변화를 줄 필요 없음 (리스케일만 함)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# flow_from_directory: 디렉토리로부터 파일 가져오기 \n",
    "train_generator=train_datagen.flow_from_directory(train_dir,\n",
    "                                                target_size=(150,150),\n",
    "                                                batch_size=20, # 20개씩 가져옴 \n",
    "                                                class_mode='binary')\n",
    "\n",
    "validation_generator=train_datagen.flow_from_directory(val_dir,\n",
    "                                                target_size=(150,150),\n",
    "                                                batch_size=20,\n",
    "                                                class_mode='binary')\n",
    "\n",
    "test_generator=train_datagen.flow_from_directory(test_dir,\n",
    "                                                target_size=(150,150),\n",
    "                                                batch_size=20,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 데이터 크기: (20, 150, 150, 3)\n",
      "배치 레이블 크기: (20,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('배치 데이터 크기:', data_batch.shape)\n",
    "    print('배치 레이블 크기:',labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 147968)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               18940032  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 19,033,409\n",
      "Trainable params: 19,033,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 36s 339ms/step - loss: 2.7547 - accuracy: 0.5206 - val_loss: 0.6703 - val_accuracy: 0.5670\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6692 - accuracy: 0.5804 - val_loss: 0.6557 - val_accuracy: 0.5980\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6531 - accuracy: 0.5983 - val_loss: 0.6593 - val_accuracy: 0.5880\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6581 - accuracy: 0.5959 - val_loss: 0.6829 - val_accuracy: 0.5300\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.6660 - accuracy: 0.5684 - val_loss: 0.6480 - val_accuracy: 0.5940\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(150,150,3),kernel_size=(3,3),filters=32),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3),filters=64),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3),filters=128),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128,activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "history=model.fit(train_generator,steps_per_epoch=100, epochs=5,\n",
    "                 validation_data=validation_generator, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6510627269744873, 0.6179999709129333]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
